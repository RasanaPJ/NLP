{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data set - Da vinchi code book review comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.read_csv('data\\sentiment_train', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6908</th>\n",
       "      <td>0</td>\n",
       "      <td>Brokeback Mountain is fucking horrible..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>0</td>\n",
       "      <td>Then snuck into Brokeback Mountain, which is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>0</td>\n",
       "      <td>, she helped me bobbypin my insanely cool hat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>0</td>\n",
       "      <td>My dad's being stupid about brokeback mountain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh, and Brokeback Mountain is a TERRIBLE movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>0</td>\n",
       "      <td>Brokeback Mountain was boring.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6914</th>\n",
       "      <td>0</td>\n",
       "      <td>So Brokeback Mountain was really depressing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6915</th>\n",
       "      <td>0</td>\n",
       "      <td>As I sit here, watching the MTV Movie Awards, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6916</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok brokeback mountain is such a horrible movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6917</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh, and Brokeback Mountain was a terrible movie.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "6908          0           Brokeback Mountain is fucking horrible..\n",
       "6909          0  Then snuck into Brokeback Mountain, which is t...\n",
       "6910          0  , she helped me bobbypin my insanely cool hat ...\n",
       "6911          0  My dad's being stupid about brokeback mountain...\n",
       "6912          0  Oh, and Brokeback Mountain is a TERRIBLE movie...\n",
       "6913          0                     Brokeback Mountain was boring.\n",
       "6914          0       So Brokeback Mountain was really depressing.\n",
       "6915          0  As I sit here, watching the MTV Movie Awards, ...\n",
       "6916          0    Ok brokeback mountain is such a horrible movie.\n",
       "6917          0   Oh, and Brokeback Mountain was a terrible movie."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          1            The Da Vinci Code book is just awesome.\n",
       "1          1  this was the first clive cussler i've ever rea...\n",
       "2          1                   i liked the Da Vinci Code a lot.\n",
       "3          1                   i liked the Da Vinci Code a lot.\n",
       "4          1  I liked the Da Vinci Code but it ultimatly did..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first five positive sentiments\n",
    "sentiment_df[sentiment_df['sentiment']==1][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>0</td>\n",
       "      <td>da vinci code was a terrible movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0</td>\n",
       "      <td>Then again, the Da Vinci code is super shitty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0</td>\n",
       "      <td>The Da Vinci Code comes out tomorrow, which su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0</td>\n",
       "      <td>i thought the da vinci code movie was really b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>0</td>\n",
       "      <td>God, Yahoo Games has this truly-awful looking ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "3943          0                da vinci code was a terrible movie.\n",
       "3944          0  Then again, the Da Vinci code is super shitty ...\n",
       "3945          0  The Da Vinci Code comes out tomorrow, which su...\n",
       "3946          0  i thought the da vinci code movie was really b...\n",
       "3947          0  God, Yahoo Games has this truly-awful looking ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first five negative sentiments\n",
    "sentiment_df[sentiment_df['sentiment']==0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6918 entries, 0 to 6917\n",
      "Data columns (total 2 columns):\n",
      "sentiment    6918 non-null int64\n",
      "text         6918 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 108.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sentiment_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "#create count plot\n",
    "ax=sn.countplot(x='sentiment', data=sentiment_df)\n",
    "#Annotate\n",
    "for p in ax.patches:\n",
    "    ax.annotate(p.get_height(), (p.get_x()+0.1, p.get_height()+50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit to create dictionary of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the dictionary from the corpus\n",
    "count_vec.fit(sentiment_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = count_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yip', 'you', 'young', 'younger', 'your', 'yuck', 'yuh', 'zach', 'zen', 'µª']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2132"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document vector\n",
    "sentiment_vec_df = count_vec.transform(sentiment_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6918, 2132)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_vec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density of matrix: 0.4434010415225908\n"
     ]
    }
   ],
   "source": [
    "# Computing number of non-zero values with respect to zero values\n",
    "print(\"Density of matrix:\", sentiment_vec_df.getnnz()*100/(sentiment_vec_df.shape[0]* sentiment_vec_df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The matrix has less than 1% non-zero values, That means this matrix is a very sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the document vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>away</th>\n",
       "      <th>awesome</th>\n",
       "      <th>awesomely</th>\n",
       "      <th>awesomeness</th>\n",
       "      <th>awesomest</th>\n",
       "      <th>awful</th>\n",
       "      <th>awkward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   away  awesome  awesomely  awesomeness  awesomest  awful  awkward\n",
       "0     0        1          0            0          0      0        0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(sentiment_vec_df.todense())\n",
    "train_df.columns = x_features\n",
    "train_df.iloc[0:1, 150:157]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the token frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sums = np.sum(sentiment_vec_df.toarray(), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  4, ...,  1, 80,  1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_frequencies_df = pd.DataFrame({'feature': x_features, 'count': token_sums})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High frequency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>the</td>\n",
       "      <td>3306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>and</td>\n",
       "      <td>2154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>harry</td>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>potter</td>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>code</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>vinci</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>da</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>mountain</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>brokeback</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>love</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  count\n",
       "1864        the   3306\n",
       "93          and   2154\n",
       "864       harry   2093\n",
       "1466     potter   2093\n",
       "355        code   2002\n",
       "2009      vinci   2001\n",
       "442          da   2001\n",
       "1272   mountain   2000\n",
       "259   brokeback   2000\n",
       "1171       love   1624"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_frequencies_df.sort_values('count', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low frequency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1228"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_frequencies_df[token_frequencies_df['count'] ==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to reduce number of features\n",
    "####  remove stop words\n",
    "####  remove low frequency and hig frequencywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(text.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['out',\n",
       " 'bottom',\n",
       " 'while',\n",
       " 'etc',\n",
       " 'mine',\n",
       " 'move',\n",
       " 'now',\n",
       " 'find',\n",
       " 'under',\n",
       " 'which',\n",
       " 'down',\n",
       " 'could',\n",
       " 'him',\n",
       " 'otherwise',\n",
       " 'perhaps',\n",
       " 'others',\n",
       " 'nine',\n",
       " 'everyone',\n",
       " 'whenever',\n",
       " 'becomes',\n",
       " 'their',\n",
       " 'his',\n",
       " 'were',\n",
       " 'whereas',\n",
       " 'few',\n",
       " 'system',\n",
       " 'side',\n",
       " 'every',\n",
       " 'cry',\n",
       " 'cannot',\n",
       " 'i',\n",
       " 'often',\n",
       " 'have',\n",
       " 'bill',\n",
       " 'two',\n",
       " 'upon',\n",
       " 'keep',\n",
       " 'five',\n",
       " 'nor',\n",
       " 'thereby',\n",
       " 'since',\n",
       " 'call',\n",
       " 'off',\n",
       " 'less',\n",
       " 'everything',\n",
       " 'hasnt',\n",
       " 'see',\n",
       " 'by',\n",
       " 'de',\n",
       " 'enough',\n",
       " 'besides',\n",
       " 'afterwards',\n",
       " 'due',\n",
       " 'ever',\n",
       " 'ie',\n",
       " 'thereafter',\n",
       " 'done',\n",
       " 'anything',\n",
       " 'wherein',\n",
       " 'rather',\n",
       " 'either',\n",
       " 'for',\n",
       " 'part',\n",
       " 'below',\n",
       " 'anyway',\n",
       " 'hundred',\n",
       " 'un',\n",
       " 'whereupon',\n",
       " 'though',\n",
       " 'alone',\n",
       " 'seeming',\n",
       " 'whose',\n",
       " 'she',\n",
       " 'between',\n",
       " 'or',\n",
       " 'yet',\n",
       " 'therefore',\n",
       " 'only',\n",
       " 'over',\n",
       " 'fill',\n",
       " 'somewhere',\n",
       " 'do',\n",
       " 'very',\n",
       " 'mostly',\n",
       " 'hereafter',\n",
       " 'thereupon',\n",
       " 'thru',\n",
       " 'get',\n",
       " 'seemed',\n",
       " 'toward',\n",
       " 'whereafter',\n",
       " 'your',\n",
       " 'amount',\n",
       " 'we',\n",
       " 'twenty',\n",
       " 'most',\n",
       " 'put',\n",
       " 'they',\n",
       " 'via',\n",
       " 'somehow',\n",
       " 'sixty',\n",
       " 'a',\n",
       " 'become',\n",
       " 'anyone',\n",
       " 'four',\n",
       " 'those',\n",
       " 'further',\n",
       " 'show',\n",
       " 'take',\n",
       " 'these',\n",
       " 'elsewhere',\n",
       " 'who',\n",
       " 'no',\n",
       " 'an',\n",
       " 'hence',\n",
       " 'many',\n",
       " 'herself',\n",
       " 'nobody',\n",
       " 'thin',\n",
       " 'con',\n",
       " 'on',\n",
       " 'when',\n",
       " 'go',\n",
       " 'in',\n",
       " 'may',\n",
       " 'against',\n",
       " 'someone',\n",
       " 'whom',\n",
       " 'are',\n",
       " 'each',\n",
       " 'fifty',\n",
       " 'can',\n",
       " 'too',\n",
       " 'behind',\n",
       " 'one',\n",
       " 'detail',\n",
       " 'none',\n",
       " 'own',\n",
       " 'herein',\n",
       " 'something',\n",
       " 'noone',\n",
       " 'except',\n",
       " 'namely',\n",
       " 'everywhere',\n",
       " 'before',\n",
       " 'yourself',\n",
       " 'already',\n",
       " 'hereby',\n",
       " 'describe',\n",
       " 'even',\n",
       " 'her',\n",
       " 'but',\n",
       " 'first',\n",
       " 'from',\n",
       " 'ourselves',\n",
       " 'has',\n",
       " 'sometime',\n",
       " 'had',\n",
       " 'am',\n",
       " 'until',\n",
       " 'whence',\n",
       " 'whither',\n",
       " 'into',\n",
       " 'hereupon',\n",
       " 'here',\n",
       " 'above',\n",
       " 'ours',\n",
       " 'how',\n",
       " 'thick',\n",
       " 'three',\n",
       " 'towards',\n",
       " 'wherever',\n",
       " 'this',\n",
       " 'whether',\n",
       " 'almost',\n",
       " 'whoever',\n",
       " 'sincere',\n",
       " 'ten',\n",
       " 'more',\n",
       " 're',\n",
       " 'although',\n",
       " 'along',\n",
       " 'fire',\n",
       " 'through',\n",
       " 'my',\n",
       " 'mill',\n",
       " 'all',\n",
       " 'give',\n",
       " 'he',\n",
       " 'name',\n",
       " 'our',\n",
       " 'why',\n",
       " 'much',\n",
       " 'us',\n",
       " 'so',\n",
       " 'whatever',\n",
       " 'whole',\n",
       " 'among',\n",
       " 'back',\n",
       " 'seem',\n",
       " 'them',\n",
       " 'meanwhile',\n",
       " 'cant',\n",
       " 'once',\n",
       " 'couldnt',\n",
       " 'co',\n",
       " 'interest',\n",
       " 'still',\n",
       " 'also',\n",
       " 'empty',\n",
       " 'nothing',\n",
       " 'after',\n",
       " 'such',\n",
       " 'being',\n",
       " 'some',\n",
       " 'myself',\n",
       " 'with',\n",
       " 'eg',\n",
       " 'me',\n",
       " 'eleven',\n",
       " 'front',\n",
       " 'around',\n",
       " 'please',\n",
       " 'that',\n",
       " 'than',\n",
       " 'across',\n",
       " 'latterly',\n",
       " 'anyhow',\n",
       " 'its',\n",
       " 'what',\n",
       " 'forty',\n",
       " 'therein',\n",
       " 'six',\n",
       " 'any',\n",
       " 'yourselves',\n",
       " 'top',\n",
       " 'be',\n",
       " 'up',\n",
       " 'sometimes',\n",
       " 'eight',\n",
       " 'latter',\n",
       " 'himself',\n",
       " 'serious',\n",
       " 'if',\n",
       " 'formerly',\n",
       " 'least',\n",
       " 'twelve',\n",
       " 'about',\n",
       " 'found',\n",
       " 'where',\n",
       " 'anywhere',\n",
       " 'been',\n",
       " 'itself',\n",
       " 'full',\n",
       " 'inc',\n",
       " 'both',\n",
       " 'thus',\n",
       " 'becoming',\n",
       " 'there',\n",
       " 'without',\n",
       " 'must',\n",
       " 'during',\n",
       " 'seems',\n",
       " 'to',\n",
       " 'well',\n",
       " 'and',\n",
       " 'became',\n",
       " 'should',\n",
       " 'yours',\n",
       " 'never',\n",
       " 'amoungst',\n",
       " 'made',\n",
       " 'third',\n",
       " 'was',\n",
       " 'whereby',\n",
       " 'nevertheless',\n",
       " 'moreover',\n",
       " 'together',\n",
       " 'throughout',\n",
       " 'because',\n",
       " 'always',\n",
       " 'however',\n",
       " 'within',\n",
       " 'beforehand',\n",
       " 'same',\n",
       " 'will',\n",
       " 'you',\n",
       " 'indeed',\n",
       " 'then',\n",
       " 'hers',\n",
       " 'thence',\n",
       " 'ltd',\n",
       " 'amongst',\n",
       " 'last',\n",
       " 'else',\n",
       " 'as',\n",
       " 'several',\n",
       " 'another',\n",
       " 'neither',\n",
       " 'would',\n",
       " 'again',\n",
       " 'of',\n",
       " 'other',\n",
       " 'nowhere',\n",
       " 'per',\n",
       " 'themselves',\n",
       " 'it',\n",
       " 'former',\n",
       " 'is',\n",
       " 'beside',\n",
       " 'next',\n",
       " 'not',\n",
       " 'might',\n",
       " 'beyond',\n",
       " 'onto',\n",
       " 'at',\n",
       " 'fifteen',\n",
       " 'the']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding our own set of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords +['movies']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec_v2 = CountVectorizer(stop_words = stopwords, \n",
    "                               min_df = 3,\n",
    "                              max_df = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.7, max_features=None, min_df=3,\n",
       "                ngram_range=(1, 1), preprocessor=None,\n",
       "                stop_words=['out', 'bottom', 'while', 'etc', 'mine', 'move',\n",
       "                            'now', 'find', 'under', 'which', 'down', 'could',\n",
       "                            'him', 'otherwise', 'perhaps', 'others', 'nine',\n",
       "                            'everyone', 'whenever', 'becomes', 'their', 'his',\n",
       "                            'were', 'whereas', 'few', 'system', 'side', 'every',\n",
       "                            'cry', 'cannot', ...],\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec_v2.fit(sentiment_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features =count_vec_v2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                     text\n",
       "0          1  The Da Vinci Code book is just awesome."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_vec_df = count_vec_v2.transform(sentiment_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features.index('awesome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_vec_df.toarray()[0:1, 15:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40550"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_vec_df.getnnz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013474760162561102"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_vec_df.getnnz()/(6918*435)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_vec_ds =pd.DataFrame(sentiment_vec_df.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "      <th>431</th>\n",
       "      <th>432</th>\n",
       "      <th>433</th>\n",
       "      <th>434</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   425  426  427  428  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   429  430  431  432  433  434  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 435 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_vec_ds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_vec_ds.columns =x_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>17</th>\n",
       "      <th>6th</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absurd</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>aching</th>\n",
       "      <th>acne</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>worthless</th>\n",
       "      <th>wotshisface</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>zen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  17  6th  absolutely  absurd  acceptable  aching  acne  action  \\\n",
       "0   0   0    0           0       0           0       0     0       0   \n",
       "1   0   0    0           0       0           0       0     0       0   \n",
       "2   0   0    0           0       0           0       0     0       0   \n",
       "3   0   0    0           0       0           0       0     0       0   \n",
       "4   0   0    0           0       0           0       0     0       0   \n",
       "\n",
       "   actually ...   world  worth  worthless  wotshisface  write  wrong  yeah  \\\n",
       "0         0 ...       0      0          0            0      0      0     0   \n",
       "1         0 ...       0      0          0            0      0      0     0   \n",
       "2         0 ...       0      0          0            0      0      0     0   \n",
       "3         0 ...       0      0          0            0      0      0     0   \n",
       "4         0 ...       0      0          0            0      0      0     0   \n",
       "\n",
       "   year  yes  zen  \n",
       "0     0    0    0  \n",
       "1     0    0    0  \n",
       "2     0    0    0  \n",
       "3     0    0    0  \n",
       "4     0    0    0  \n",
       "\n",
       "[5 rows x 435 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_vec_ds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_vec_ds['sentiment'] = sentiment_df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d7392f6128>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.barplot(x = 'sentiment',\n",
    "           y = 'awesome',           \n",
    "           data = sentiment_vec_ds,\n",
    "           estimator = sum\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sentiment_vec_ds[x_features],\n",
    "                                  sentiment_vec_ds['sentiment'],\n",
    "                                  train_size = 0.8,\n",
    "                                  random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_vl = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_vl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_vl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_vl = confusion_matrix(y_test, y_pred, [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[801,   3],\n",
       "       [ 23, 557]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       580\n",
      "           1       0.97      1.00      0.98       804\n",
      "\n",
      "    accuracy                           0.98      1384\n",
      "   macro avg       0.98      0.98      0.98      1384\n",
      "weighted avg       0.98      0.98      0.98      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9720873786407767"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "801/(23+801)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_v1 =RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {'n_estimators': [100],\n",
    "            'criterion' : ['gini'],\n",
    "            'max_depth' : [10,15],\n",
    "            'max_features': [0.1, 0.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_v1 = GridSearchCV(rf_v1,\n",
    "                      param_grid = rf_params,\n",
    "                      cv = 10,\n",
    "                      scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': [10, 15],\n",
       "                         'max_features': [0.1, 0.2], 'n_estimators': [100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_v1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 15,\n",
       " 'max_features': 0.2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_v1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=15, max_features=0.2, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_v1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final = grid_v1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_df = pd.DataFrame({'feature' : x_features,\n",
    "                              'importance': rf_final.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>love</td>\n",
       "      <td>0.184805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>awesome</td>\n",
       "      <td>0.139662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>sucked</td>\n",
       "      <td>0.083592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>sucks</td>\n",
       "      <td>0.066139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>hate</td>\n",
       "      <td>0.057604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>mission</td>\n",
       "      <td>0.043067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>loved</td>\n",
       "      <td>0.041332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>impossible</td>\n",
       "      <td>0.040159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>like</td>\n",
       "      <td>0.038224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>suck</td>\n",
       "      <td>0.034759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>stupid</td>\n",
       "      <td>0.031230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>0.027617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>movie</td>\n",
       "      <td>0.018997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>depressing</td>\n",
       "      <td>0.013996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>horrible</td>\n",
       "      <td>0.013172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>terrible</td>\n",
       "      <td>0.007895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>boring</td>\n",
       "      <td>0.007849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>mountain</td>\n",
       "      <td>0.007334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>just</td>\n",
       "      <td>0.006029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>code</td>\n",
       "      <td>0.005658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance\n",
       "245        love    0.184805\n",
       "19      awesome    0.139662\n",
       "365      sucked    0.083592\n",
       "367       sucks    0.066139\n",
       "173        hate    0.057604\n",
       "263     mission    0.043067\n",
       "246       loved    0.041332\n",
       "198  impossible    0.040159\n",
       "230        like    0.038224\n",
       "364        suck    0.034759\n",
       "363      stupid    0.031230\n",
       "24    beautiful    0.027617\n",
       "269       movie    0.018997\n",
       "91   depressing    0.013996\n",
       "193    horrible    0.013172\n",
       "377    terrible    0.007895\n",
       "39       boring    0.007849\n",
       "267    mountain    0.007334\n",
       "212        just    0.006029\n",
       "56         code    0.005658"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp_df.sort_values('importance', ascending = False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Stemming and lemmatization and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stemmed_words( doc) :\n",
    "    stemmed_words = [stemmer.stem(x) for x in analyzer(doc)]    \n",
    "    final_words = [word for word in stemmed_words if word not in stopwords]\n",
    "    return final_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'play', 'love']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stemmed_words(\"the is loved playing lovely\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_vec = TfidfVectorizer(tokenizer=get_stemmed_words,ngram_range=(1,2), max_df=0.8, min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=0.8, max_features=None,\n",
       "                min_df=3, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function get_stemmed_words at 0x000001D73D90F620>,\n",
       "                use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfid_vec.fit(sentiment_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_df = tfid_vec.transform(sentiment_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = tfid_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features.index('awesom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfid_df.toarray()[0:1, 15:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>10 thing</th>\n",
       "      <th>17</th>\n",
       "      <th>6th</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absolut awesom</th>\n",
       "      <th>absolut hate</th>\n",
       "      <th>absolut love</th>\n",
       "      <th>absurd</th>\n",
       "      <th>accept</th>\n",
       "      <th>...</th>\n",
       "      <th>wotshisfac</th>\n",
       "      <th>wotshisfac need</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>ye</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yeah got</th>\n",
       "      <th>year</th>\n",
       "      <th>zen</th>\n",
       "      <th>zen da</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  10 thing   17  6th  absolut  absolut awesom  absolut hate  \\\n",
       "0  0.0       0.0  0.0  0.0      0.0             0.0           0.0   \n",
       "1  0.0       0.0  0.0  0.0      0.0             0.0           0.0   \n",
       "2  0.0       0.0  0.0  0.0      0.0             0.0           0.0   \n",
       "3  0.0       0.0  0.0  0.0      0.0             0.0           0.0   \n",
       "4  0.0       0.0  0.0  0.0      0.0             0.0           0.0   \n",
       "\n",
       "   absolut love  absurd  accept   ...    wotshisfac  wotshisfac need  write  \\\n",
       "0           0.0     0.0     0.0   ...           0.0              0.0    0.0   \n",
       "1           0.0     0.0     0.0   ...           0.0              0.0    0.0   \n",
       "2           0.0     0.0     0.0   ...           0.0              0.0    0.0   \n",
       "3           0.0     0.0     0.0   ...           0.0              0.0    0.0   \n",
       "4           0.0     0.0     0.0   ...           0.0              0.0    0.0   \n",
       "\n",
       "   wrong   ye  yeah  yeah got  year  zen  zen da  \n",
       "0    0.0  0.0   0.0       0.0   0.0  0.0     0.0  \n",
       "1    0.0  0.0   0.0       0.0   0.0  0.0     0.0  \n",
       "2    0.0  0.0   0.0       0.0   0.0  0.0     0.0  \n",
       "3    0.0  0.0   0.0       0.0   0.0  0.0     0.0  \n",
       "4    0.0  0.0   0.0       0.0   0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 900 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_tfid_vec_ds =pd.DataFrame(tfid_df.todense(), columns=x_features)\n",
    "sentiment_tfid_vec_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_tfid_vec_ds['sentiment'] = sentiment_df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentiment_tfid_vec_ds[x_features],\n",
    "                                  sentiment_tfid_vec_ds['sentiment'],\n",
    "                                  train_size = 0.8,\n",
    "                                  random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_v2 =RandomForestClassifier()\n",
    "rf_params = {'n_estimators': [100],\n",
    "            'criterion' : ['gini'],\n",
    "            'max_depth' : [10,15],\n",
    "            'max_features': [0.1, 0.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_v2 = GridSearchCV(rf_v2,\n",
    "                      param_grid = rf_params,\n",
    "                      cv = 10,\n",
    "                      scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': [10, 15],\n",
       "                         'max_features': [0.1, 0.2], 'n_estimators': [100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_v1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_v1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final = grid_v1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_df = pd.DataFrame({'feature' : x_features,\n",
    "                              'importance': rf_final.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_df.sort_values('importance', ascending = False)[0:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
